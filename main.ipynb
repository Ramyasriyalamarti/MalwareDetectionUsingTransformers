{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JWt6FjCCEM_U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x1=pd.read_csv('/content/drive/MyDrive/malware_datasets/final-apipackages-finaldataset.csv')\n",
        "x2=pd.read_csv('/content/drive/MyDrive/malware_datasets/final-apicall-finaldataset.csv').iloc[:,1:]\n",
        "x3=pd.read_csv('/content/drive/MyDrive/malware_datasets/final_opcodes_finaldataset.csv').iloc[:,1:]\n",
        "x4=pd.read_csv('/content/drive/MyDrive/malware_datasets/final_per_be_mal_final.csv').iloc[:,1:]"
      ],
      "metadata": {
        "id": "WOpmgxDEEekC"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=pd.concat([x1, x2, x3, x4], axis=1)"
      ],
      "metadata": {
        "id": "WLJN6ObLEhBd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = data.drop(columns=['class'])\n",
        "y = data['class']"
      ],
      "metadata": {
        "id": "Cjd8JBNaEzm-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "class TransformerBlock(layers.Layer):\n",
        "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
        "        super(TransformerBlock, self).__init__()\n",
        "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
        "        self.ffn = models.Sequential(\n",
        "            [layers.Dense(ff_dim, activation=\"relu\"), layers.Dense(embed_dim)]\n",
        "        )\n",
        "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.dropout1 = layers.Dropout(rate)\n",
        "        self.dropout2 = layers.Dropout(rate)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        inputs = tf.expand_dims(inputs, axis=1)\n",
        "\n",
        "        attn_output = self.att(inputs, inputs)\n",
        "        attn_output = self.dropout1(attn_output)\n",
        "\n",
        "\n",
        "        out1 = self.layernorm1(inputs + attn_output)\n",
        "\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output)\n",
        "\n",
        "        return self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oTHlEGY5E11H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l=[]\n",
        "for num_heads in range(2,13):\n",
        "  embed_dim = 32\n",
        "  ff_dim = 32\n",
        "  input_shape = X_train_scaled.shape[1]\n",
        "  inputs = layers.Input(shape=(input_shape,))\n",
        "  x = layers.Dense(embed_dim)(inputs)\n",
        "  transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "  x = transformer_block(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(64, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.1)(x)\n",
        "  x = layers.Dense(32, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.1)(x)\n",
        "  outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = models.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  model.fit(X_train_scaled, y_train, epochs=45, batch_size=32, validation_split=0.25)\n",
        "  loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "  k.append([num_heads,accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "khC_BHkIFHog",
        "outputId": "9f18c767-475d-474e-8e12-fd769be4c122"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 78ms/step - accuracy: 0.9271 - loss: 0.2032 - val_accuracy: 0.9880 - val_loss: 0.0328\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0481 - val_accuracy: 0.9841 - val_loss: 0.0384\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0250 - val_accuracy: 0.9602 - val_loss: 0.1143\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9902 - loss: 0.0242 - val_accuracy: 0.9801 - val_loss: 0.0742\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.0204 - val_accuracy: 0.9841 - val_loss: 0.0561\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9955 - loss: 0.0135 - val_accuracy: 0.9781 - val_loss: 0.0657\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0100 - val_accuracy: 0.9821 - val_loss: 0.0693\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9958 - loss: 0.0134 - val_accuracy: 0.9841 - val_loss: 0.0451\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9976 - loss: 0.0071 - val_accuracy: 0.9851 - val_loss: 0.0611\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9934 - loss: 0.0165 - val_accuracy: 0.9861 - val_loss: 0.0491\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0094 - val_accuracy: 0.9880 - val_loss: 0.0369\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9841 - val_loss: 0.0577\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0160 - val_accuracy: 0.9861 - val_loss: 0.0478\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9542 - val_loss: 0.2031\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9890 - loss: 0.0243 - val_accuracy: 0.9861 - val_loss: 0.0585\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0095 - val_accuracy: 0.9861 - val_loss: 0.0398\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0050 - val_accuracy: 0.9900 - val_loss: 0.0548\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0172 - val_accuracy: 0.9890 - val_loss: 0.0448\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0081 - val_accuracy: 0.9890 - val_loss: 0.0488\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0062 - val_accuracy: 0.9861 - val_loss: 0.0405\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0054 - val_accuracy: 0.9880 - val_loss: 0.0464\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0038 - val_accuracy: 0.9880 - val_loss: 0.0405\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9861 - val_loss: 0.0485\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0016 - val_accuracy: 0.9861 - val_loss: 0.0754\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0152 - val_accuracy: 0.9851 - val_loss: 0.0535\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0038 - val_accuracy: 0.9861 - val_loss: 0.0469\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0015 - val_accuracy: 0.9890 - val_loss: 0.0568\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0213 - val_accuracy: 0.9871 - val_loss: 0.0455\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.9861 - val_loss: 0.0505\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0026 - val_accuracy: 0.9880 - val_loss: 0.0587\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 9.4816e-04 - val_accuracy: 0.9861 - val_loss: 0.0622\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 1.8474e-04 - val_accuracy: 0.9851 - val_loss: 0.0647\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0018 - val_accuracy: 0.9841 - val_loss: 0.0642\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0045 - val_accuracy: 0.9851 - val_loss: 0.0607\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.9831 - val_loss: 0.0669\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0036 - val_accuracy: 0.9831 - val_loss: 0.0508\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0016 - val_accuracy: 0.9831 - val_loss: 0.0660\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0046 - val_accuracy: 0.9861 - val_loss: 0.0652\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 6.0756e-04 - val_accuracy: 0.9880 - val_loss: 0.0802\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9954 - loss: 0.0147 - val_accuracy: 0.9871 - val_loss: 0.0683\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0019 - val_accuracy: 0.9861 - val_loss: 0.0944\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0032 - val_accuracy: 0.9841 - val_loss: 0.0853\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 9.3824e-04 - val_accuracy: 0.9861 - val_loss: 0.0953\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0054 - val_accuracy: 0.9861 - val_loss: 0.0556\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9851 - val_loss: 0.0676\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9848 - loss: 0.0510 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 3, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 74ms/step - accuracy: 0.9050 - loss: 0.2358 - val_accuracy: 0.9861 - val_loss: 0.0295\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0319 - val_accuracy: 0.9851 - val_loss: 0.0394\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9926 - loss: 0.0206 - val_accuracy: 0.9781 - val_loss: 0.0618\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0161 - val_accuracy: 0.9841 - val_loss: 0.0532\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0124 - val_accuracy: 0.9861 - val_loss: 0.0405\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0170 - val_accuracy: 0.9861 - val_loss: 0.0390\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0095 - val_accuracy: 0.9821 - val_loss: 0.0697\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0078 - val_accuracy: 0.9851 - val_loss: 0.0455\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.0184 - val_accuracy: 0.9871 - val_loss: 0.0523\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0137 - val_accuracy: 0.9821 - val_loss: 0.0669\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9945 - loss: 0.0129 - val_accuracy: 0.9851 - val_loss: 0.0696\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0156 - val_accuracy: 0.9871 - val_loss: 0.0484\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9967 - loss: 0.0134 - val_accuracy: 0.9871 - val_loss: 0.0521\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9977 - loss: 0.0054 - val_accuracy: 0.9861 - val_loss: 0.0514\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0087 - val_accuracy: 0.9821 - val_loss: 0.0861\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0101 - val_accuracy: 0.9871 - val_loss: 0.0651\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0035 - val_accuracy: 0.9861 - val_loss: 0.0680\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9988 - loss: 0.0015 - val_accuracy: 0.9851 - val_loss: 0.0923\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9969 - loss: 0.0163 - val_accuracy: 0.9781 - val_loss: 0.0921\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9958 - loss: 0.0146 - val_accuracy: 0.9841 - val_loss: 0.0591\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9967 - loss: 0.0077 - val_accuracy: 0.9861 - val_loss: 0.0741\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9978 - loss: 0.0117 - val_accuracy: 0.9861 - val_loss: 0.0765\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9861 - val_loss: 0.0572\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9986 - loss: 0.0035 - val_accuracy: 0.9871 - val_loss: 0.0594\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9851 - val_loss: 0.0736\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9995 - loss: 0.0014 - val_accuracy: 0.9612 - val_loss: 0.1721\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9829 - loss: 0.0590 - val_accuracy: 0.9861 - val_loss: 0.0675\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0052 - val_accuracy: 0.9861 - val_loss: 0.0741\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9861 - val_loss: 0.0655\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0083 - val_accuracy: 0.9851 - val_loss: 0.0804\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9998 - loss: 0.0012 - val_accuracy: 0.9841 - val_loss: 0.0790\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0029 - val_accuracy: 0.9851 - val_loss: 0.0807\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0025 - val_accuracy: 0.9831 - val_loss: 0.1132\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9944 - loss: 0.0129 - val_accuracy: 0.9811 - val_loss: 0.1251\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0042 - val_accuracy: 0.9811 - val_loss: 0.1107\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0017 - val_accuracy: 0.9851 - val_loss: 0.0798\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0018 - val_accuracy: 0.9811 - val_loss: 0.1445\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0045 - val_accuracy: 0.9851 - val_loss: 0.0551\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0143 - val_accuracy: 0.9890 - val_loss: 0.0675\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0085 - val_accuracy: 0.9851 - val_loss: 0.0840\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0032 - val_accuracy: 0.9861 - val_loss: 0.0778\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0031 - val_accuracy: 0.9861 - val_loss: 0.0834\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0052 - val_accuracy: 0.9871 - val_loss: 0.0839\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9968 - loss: 0.0063 - val_accuracy: 0.9851 - val_loss: 0.0753\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 6.3253e-04 - val_accuracy: 0.9851 - val_loss: 0.0818\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0437\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 72ms/step - accuracy: 0.9085 - loss: 0.2389 - val_accuracy: 0.9821 - val_loss: 0.0472\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0431 - val_accuracy: 0.9841 - val_loss: 0.0388\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9948 - loss: 0.0162 - val_accuracy: 0.9761 - val_loss: 0.0570\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0169 - val_accuracy: 0.9861 - val_loss: 0.0356\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9905 - loss: 0.0232 - val_accuracy: 0.9831 - val_loss: 0.0417\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9937 - loss: 0.0157 - val_accuracy: 0.9851 - val_loss: 0.0406\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0087 - val_accuracy: 0.9861 - val_loss: 0.0619\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0063 - val_accuracy: 0.9880 - val_loss: 0.0543\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0150 - val_accuracy: 0.9861 - val_loss: 0.0412\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0095 - val_accuracy: 0.9851 - val_loss: 0.0477\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0082 - val_accuracy: 0.9721 - val_loss: 0.1141\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0133 - val_accuracy: 0.9861 - val_loss: 0.0439\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0067 - val_accuracy: 0.9851 - val_loss: 0.0524\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0085 - val_accuracy: 0.9821 - val_loss: 0.0689\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0155 - val_accuracy: 0.9841 - val_loss: 0.0823\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0169 - val_accuracy: 0.9851 - val_loss: 0.0697\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0037 - val_accuracy: 0.9841 - val_loss: 0.0751\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0043 - val_accuracy: 0.9841 - val_loss: 0.0696\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0069 - val_accuracy: 0.9841 - val_loss: 0.0556\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0039 - val_accuracy: 0.9841 - val_loss: 0.0654\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0035 - val_accuracy: 0.9880 - val_loss: 0.0875\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0058 - val_accuracy: 0.9841 - val_loss: 0.0771\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0042 - val_accuracy: 0.9721 - val_loss: 0.1068\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0218 - val_accuracy: 0.9831 - val_loss: 0.0833\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0046 - val_accuracy: 0.9861 - val_loss: 0.0745\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0040 - val_accuracy: 0.9821 - val_loss: 0.0729\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0028 - val_accuracy: 0.9841 - val_loss: 0.0703\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0135 - val_accuracy: 0.9841 - val_loss: 0.0622\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0012 - val_accuracy: 0.9880 - val_loss: 0.0825\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0047 - val_accuracy: 0.9841 - val_loss: 0.1023\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9944 - loss: 0.0153 - val_accuracy: 0.9821 - val_loss: 0.0702\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9831 - val_loss: 0.0900\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0013 - val_accuracy: 0.9841 - val_loss: 0.0629\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0042 - val_accuracy: 0.9851 - val_loss: 0.0763\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0035 - val_accuracy: 0.9851 - val_loss: 0.0935\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0036 - val_accuracy: 0.9841 - val_loss: 0.0669\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0023 - val_accuracy: 0.9851 - val_loss: 0.1116\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0094 - val_accuracy: 0.9861 - val_loss: 0.0870\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0021 - val_accuracy: 0.9871 - val_loss: 0.0961\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0027 - val_accuracy: 0.9851 - val_loss: 0.0942\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0010 - val_accuracy: 0.9880 - val_loss: 0.0627\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0021 - val_accuracy: 0.9761 - val_loss: 0.0919\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0122 - val_accuracy: 0.9880 - val_loss: 0.1002\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0053 - val_accuracy: 0.9801 - val_loss: 0.1296\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0146 - val_accuracy: 0.9831 - val_loss: 0.1063\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 0.0491\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 5, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 64ms/step - accuracy: 0.8906 - loss: 0.2725 - val_accuracy: 0.9900 - val_loss: 0.0341\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0409 - val_accuracy: 0.9851 - val_loss: 0.0387\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0223 - val_accuracy: 0.9811 - val_loss: 0.0593\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9874 - loss: 0.0278 - val_accuracy: 0.9880 - val_loss: 0.0589\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0233 - val_accuracy: 0.9841 - val_loss: 0.0494\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0120 - val_accuracy: 0.9821 - val_loss: 0.0751\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9767 - loss: 0.0954 - val_accuracy: 0.9731 - val_loss: 0.0801\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0119 - val_accuracy: 0.9871 - val_loss: 0.0557\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0164 - val_accuracy: 0.9851 - val_loss: 0.0477\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0126 - val_accuracy: 0.9861 - val_loss: 0.0594\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0129 - val_accuracy: 0.9851 - val_loss: 0.0520\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0108 - val_accuracy: 0.9871 - val_loss: 0.0583\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0133 - val_accuracy: 0.9861 - val_loss: 0.0537\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0064 - val_accuracy: 0.9831 - val_loss: 0.0694\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0084 - val_accuracy: 0.9851 - val_loss: 0.0642\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0106 - val_accuracy: 0.9841 - val_loss: 0.0520\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0017 - val_accuracy: 0.9821 - val_loss: 0.0691\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0120 - val_accuracy: 0.9851 - val_loss: 0.0606\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0074 - val_accuracy: 0.9821 - val_loss: 0.0604\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9977 - loss: 0.0064 - val_accuracy: 0.9851 - val_loss: 0.0927\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9978 - loss: 0.0096 - val_accuracy: 0.9841 - val_loss: 0.0898\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9990 - loss: 0.0048 - val_accuracy: 0.9851 - val_loss: 0.0891\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9979 - loss: 0.0060 - val_accuracy: 0.9841 - val_loss: 0.0830\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0028 - val_accuracy: 0.9851 - val_loss: 0.0996\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.9861 - val_loss: 0.0732\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0120 - val_accuracy: 0.9821 - val_loss: 0.0844\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0026 - val_accuracy: 0.9851 - val_loss: 0.0767\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0071 - val_accuracy: 0.9841 - val_loss: 0.0663\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0031 - val_accuracy: 0.9841 - val_loss: 0.0712\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 9.6360e-04 - val_accuracy: 0.9821 - val_loss: 0.1129\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0184 - val_accuracy: 0.9851 - val_loss: 0.0692\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 7.9670e-04 - val_accuracy: 0.9821 - val_loss: 0.0879\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.9397e-04 - val_accuracy: 0.9871 - val_loss: 0.0790\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0024 - val_accuracy: 0.9851 - val_loss: 0.0733\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0013 - val_accuracy: 0.9831 - val_loss: 0.0994\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0095 - val_accuracy: 0.9841 - val_loss: 0.0720\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6282e-04 - val_accuracy: 0.9890 - val_loss: 0.0549\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0180 - val_accuracy: 0.9861 - val_loss: 0.0546\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0068 - val_accuracy: 0.9880 - val_loss: 0.0557\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0028 - val_accuracy: 0.9880 - val_loss: 0.0640\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0067 - val_accuracy: 0.9851 - val_loss: 0.0632\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0018 - val_accuracy: 0.9841 - val_loss: 0.0738\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5311e-04 - val_accuracy: 0.9861 - val_loss: 0.1003\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9998 - loss: 4.6241e-04 - val_accuracy: 0.9831 - val_loss: 0.1233\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9948 - loss: 0.0223 - val_accuracy: 0.9831 - val_loss: 0.0881\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 6, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 73ms/step - accuracy: 0.9092 - loss: 0.2048 - val_accuracy: 0.9861 - val_loss: 0.0405\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0300 - val_accuracy: 0.9811 - val_loss: 0.0453\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9936 - loss: 0.0184 - val_accuracy: 0.9831 - val_loss: 0.0588\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.0276 - val_accuracy: 0.9552 - val_loss: 0.1421\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.3188 - val_accuracy: 0.9821 - val_loss: 0.0511\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0179 - val_accuracy: 0.9801 - val_loss: 0.0608\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9963 - loss: 0.0106 - val_accuracy: 0.9831 - val_loss: 0.0557\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0062 - val_accuracy: 0.9831 - val_loss: 0.0576\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0083 - val_accuracy: 0.9831 - val_loss: 0.0602\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0111 - val_accuracy: 0.9831 - val_loss: 0.0549\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0069 - val_accuracy: 0.9811 - val_loss: 0.0792\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0055 - val_accuracy: 0.9861 - val_loss: 0.0564\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0085 - val_accuracy: 0.9851 - val_loss: 0.0804\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0117 - val_accuracy: 0.9831 - val_loss: 0.0493\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0035 - val_accuracy: 0.9761 - val_loss: 0.0883\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0129 - val_accuracy: 0.9821 - val_loss: 0.0742\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0069 - val_accuracy: 0.9831 - val_loss: 0.0691\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0017 - val_accuracy: 0.9851 - val_loss: 0.0802\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0061 - val_accuracy: 0.9841 - val_loss: 0.0608\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0034 - val_accuracy: 0.9851 - val_loss: 0.0639\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0158 - val_accuracy: 0.9890 - val_loss: 0.0827\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0041 - val_accuracy: 0.9841 - val_loss: 0.0771\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.8275e-04 - val_accuracy: 0.9861 - val_loss: 0.0683\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0026 - val_accuracy: 0.9890 - val_loss: 0.0504\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0063 - val_accuracy: 0.9851 - val_loss: 0.0542\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0035 - val_accuracy: 0.9851 - val_loss: 0.0628\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0024 - val_accuracy: 0.9851 - val_loss: 0.0776\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0049 - val_accuracy: 0.9831 - val_loss: 0.0713\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0084 - val_accuracy: 0.9801 - val_loss: 0.1044\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0047 - val_accuracy: 0.9851 - val_loss: 0.0611\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0068 - val_accuracy: 0.9880 - val_loss: 0.0521\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0082 - val_accuracy: 0.9841 - val_loss: 0.0533\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0039 - val_accuracy: 0.9871 - val_loss: 0.0507\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0015 - val_accuracy: 0.9871 - val_loss: 0.0678\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9992 - loss: 0.0025 - val_accuracy: 0.9861 - val_loss: 0.0612\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 1.0000 - loss: 4.0820e-04 - val_accuracy: 0.9890 - val_loss: 0.0766\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9982 - loss: 0.0136 - val_accuracy: 0.9871 - val_loss: 0.0649\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0071 - val_accuracy: 0.9890 - val_loss: 0.0892\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0125 - val_accuracy: 0.9861 - val_loss: 0.0604\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0042 - val_accuracy: 0.9861 - val_loss: 0.0594\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0019 - val_accuracy: 0.9841 - val_loss: 0.0558\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0175 - val_accuracy: 0.9880 - val_loss: 0.0615\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0021 - val_accuracy: 0.9861 - val_loss: 0.0801\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4797e-04 - val_accuracy: 0.9871 - val_loss: 0.0706\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0084 - val_accuracy: 0.9890 - val_loss: 0.0422\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9932 - loss: 0.0188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 7, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 69ms/step - accuracy: 0.8707 - loss: 0.2897 - val_accuracy: 0.9880 - val_loss: 0.0329\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0375 - val_accuracy: 0.9831 - val_loss: 0.0460\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0230 - val_accuracy: 0.9841 - val_loss: 0.0399\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0221 - val_accuracy: 0.9841 - val_loss: 0.0378\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0124 - val_accuracy: 0.9851 - val_loss: 0.0502\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0196 - val_accuracy: 0.9811 - val_loss: 0.0703\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0181 - val_accuracy: 0.9861 - val_loss: 0.0427\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0080 - val_accuracy: 0.9861 - val_loss: 0.0522\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0079 - val_accuracy: 0.9811 - val_loss: 0.0611\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0203 - val_accuracy: 0.9841 - val_loss: 0.0496\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0138 - val_accuracy: 0.9691 - val_loss: 0.0810\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0231 - val_accuracy: 0.9771 - val_loss: 0.0824\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0143 - val_accuracy: 0.9861 - val_loss: 0.0597\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0213 - val_accuracy: 0.9880 - val_loss: 0.0375\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0055 - val_accuracy: 0.9880 - val_loss: 0.0374\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0070 - val_accuracy: 0.9871 - val_loss: 0.0362\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0029 - val_accuracy: 0.9900 - val_loss: 0.0479\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.9880 - val_loss: 0.0414\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0034 - val_accuracy: 0.9781 - val_loss: 0.1021\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0154 - val_accuracy: 0.9871 - val_loss: 0.0357\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0030 - val_accuracy: 0.9890 - val_loss: 0.0379\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0031 - val_accuracy: 0.9861 - val_loss: 0.0393\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0066 - val_accuracy: 0.9871 - val_loss: 0.0430\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9995 - loss: 0.0030 - val_accuracy: 0.9880 - val_loss: 0.0350\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9995 - loss: 0.0025 - val_accuracy: 0.9851 - val_loss: 0.0657\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9871 - val_loss: 0.0613\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0051 - val_accuracy: 0.9841 - val_loss: 0.0640\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0068 - val_accuracy: 0.9880 - val_loss: 0.0506\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0022 - val_accuracy: 0.9890 - val_loss: 0.0442\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9871 - val_loss: 0.0546\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9880 - val_loss: 0.0470\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0042 - val_accuracy: 0.9831 - val_loss: 0.0974\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0071 - val_accuracy: 0.9751 - val_loss: 0.1698\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0159 - val_accuracy: 0.9871 - val_loss: 0.0925\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0061 - val_accuracy: 0.9861 - val_loss: 0.0583\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0043 - val_accuracy: 0.9890 - val_loss: 0.0648\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.9890 - val_loss: 0.0505\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0035 - val_accuracy: 0.9871 - val_loss: 0.0696\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0010 - val_accuracy: 0.9890 - val_loss: 0.0753\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0110 - val_accuracy: 0.9880 - val_loss: 0.0564\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0018 - val_accuracy: 0.9871 - val_loss: 0.0592\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0022 - val_accuracy: 0.9861 - val_loss: 0.0703\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0031 - val_accuracy: 0.9861 - val_loss: 0.0643\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0036 - val_accuracy: 0.9871 - val_loss: 0.0649\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 8.2864e-04 - val_accuracy: 0.9880 - val_loss: 0.0518\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0438\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 59ms/step - accuracy: 0.9274 - loss: 0.2267 - val_accuracy: 0.9890 - val_loss: 0.0343\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9880 - loss: 0.0352 - val_accuracy: 0.9851 - val_loss: 0.0376\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0202 - val_accuracy: 0.9910 - val_loss: 0.0317\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9942 - loss: 0.0162 - val_accuracy: 0.9880 - val_loss: 0.0322\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9947 - loss: 0.0156 - val_accuracy: 0.9871 - val_loss: 0.0408\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0135 - val_accuracy: 0.9900 - val_loss: 0.0467\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9971 - loss: 0.0075 - val_accuracy: 0.9861 - val_loss: 0.0461\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9916 - loss: 0.0196 - val_accuracy: 0.9890 - val_loss: 0.0497\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0095 - val_accuracy: 0.9871 - val_loss: 0.0468\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0102 - val_accuracy: 0.9831 - val_loss: 0.0569\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0104 - val_accuracy: 0.9841 - val_loss: 0.0788\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0178 - val_accuracy: 0.9841 - val_loss: 0.0511\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0083 - val_accuracy: 0.9851 - val_loss: 0.0608\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0163 - val_accuracy: 0.9861 - val_loss: 0.0544\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0143 - val_accuracy: 0.9861 - val_loss: 0.0720\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0106 - val_accuracy: 0.9851 - val_loss: 0.0922\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9861 - val_loss: 0.0508\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0082 - val_accuracy: 0.9851 - val_loss: 0.0615\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0078 - val_accuracy: 0.9811 - val_loss: 0.0930\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0155 - val_accuracy: 0.9861 - val_loss: 0.0443\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0056 - val_accuracy: 0.9831 - val_loss: 0.0660\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0054 - val_accuracy: 0.9841 - val_loss: 0.0651\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0051 - val_accuracy: 0.9751 - val_loss: 0.1031\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0118 - val_accuracy: 0.9831 - val_loss: 0.0703\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0028 - val_accuracy: 0.9861 - val_loss: 0.0856\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0036 - val_accuracy: 0.9851 - val_loss: 0.0799\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9851 - val_loss: 0.0667\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0159 - val_accuracy: 0.9861 - val_loss: 0.0647\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0067 - val_accuracy: 0.9811 - val_loss: 0.1047\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0066 - val_accuracy: 0.9811 - val_loss: 0.0791\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0039 - val_accuracy: 0.9811 - val_loss: 0.1134\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 8.6230e-04 - val_accuracy: 0.9831 - val_loss: 0.1238\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9990 - loss: 0.0051 - val_accuracy: 0.9811 - val_loss: 0.1317\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9926 - loss: 0.0114 - val_accuracy: 0.9801 - val_loss: 0.0982\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.9831 - val_loss: 0.1347\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9811 - val_loss: 0.1453\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 0.9851 - val_loss: 0.0974\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 9.9428e-04 - val_accuracy: 0.9791 - val_loss: 0.2063\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0461 - val_accuracy: 0.9861 - val_loss: 0.0811\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9861 - val_loss: 0.0815\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0029 - val_accuracy: 0.9851 - val_loss: 0.0849\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0026 - val_accuracy: 0.9851 - val_loss: 0.0974\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0042 - val_accuracy: 0.9851 - val_loss: 0.0816\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.6197e-04 - val_accuracy: 0.9841 - val_loss: 0.1019\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.5084e-04 - val_accuracy: 0.9801 - val_loss: 0.1294\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9804 - loss: 0.1057\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 9, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 67ms/step - accuracy: 0.8830 - loss: 0.2946 - val_accuracy: 0.9831 - val_loss: 0.0441\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9867 - loss: 0.0378 - val_accuracy: 0.9811 - val_loss: 0.0449\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9921 - loss: 0.0252 - val_accuracy: 0.9851 - val_loss: 0.0469\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0128 - val_accuracy: 0.9831 - val_loss: 0.0501\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0104 - val_accuracy: 0.9851 - val_loss: 0.0416\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0147 - val_accuracy: 0.9861 - val_loss: 0.0512\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0083 - val_accuracy: 0.9861 - val_loss: 0.0536\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0065 - val_accuracy: 0.9841 - val_loss: 0.0570\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0117 - val_accuracy: 0.9741 - val_loss: 0.0843\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9862 - loss: 0.0302 - val_accuracy: 0.9851 - val_loss: 0.0603\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0055 - val_accuracy: 0.9831 - val_loss: 0.0699\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0103 - val_accuracy: 0.9841 - val_loss: 0.0789\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9991 - loss: 0.0042 - val_accuracy: 0.9851 - val_loss: 0.0624\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0085 - val_accuracy: 0.9841 - val_loss: 0.0639\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0097 - val_accuracy: 0.9861 - val_loss: 0.0602\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9982 - loss: 0.0070 - val_accuracy: 0.9861 - val_loss: 0.0768\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9980 - loss: 0.0049 - val_accuracy: 0.9841 - val_loss: 0.0765\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0047 - val_accuracy: 0.9861 - val_loss: 0.0782\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0138 - val_accuracy: 0.9801 - val_loss: 0.1078\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0094 - val_accuracy: 0.9861 - val_loss: 0.0981\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0057 - val_accuracy: 0.9851 - val_loss: 0.0592\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0038 - val_accuracy: 0.9841 - val_loss: 0.0845\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0043 - val_accuracy: 0.9831 - val_loss: 0.0787\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.9841 - val_loss: 0.1102\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9841 - val_loss: 0.1022\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0084 - val_accuracy: 0.9831 - val_loss: 0.0763\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0139 - val_accuracy: 0.9871 - val_loss: 0.0607\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0021 - val_accuracy: 0.9821 - val_loss: 0.1219\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0120 - val_accuracy: 0.9851 - val_loss: 0.0770\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0025 - val_accuracy: 0.9851 - val_loss: 0.0693\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 4.2694e-04 - val_accuracy: 0.9841 - val_loss: 0.1286\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9936 - loss: 0.0193 - val_accuracy: 0.9851 - val_loss: 0.1047\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9986 - loss: 0.0040 - val_accuracy: 0.9841 - val_loss: 0.0839\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0065 - val_accuracy: 0.9851 - val_loss: 0.1215\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0043 - val_accuracy: 0.9841 - val_loss: 0.0662\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0110 - val_accuracy: 0.9871 - val_loss: 0.0788\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9831 - val_loss: 0.0606\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9801 - val_loss: 0.0876\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0203 - val_accuracy: 0.9831 - val_loss: 0.0894\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0150 - val_accuracy: 0.9851 - val_loss: 0.0725\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9988 - loss: 0.0038 - val_accuracy: 0.9821 - val_loss: 0.0901\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9996 - loss: 0.0017 - val_accuracy: 0.9811 - val_loss: 0.0844\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0062 - val_accuracy: 0.9811 - val_loss: 0.1119\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0025 - val_accuracy: 0.9801 - val_loss: 0.0977\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0022 - val_accuracy: 0.9801 - val_loss: 0.1351\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0382\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 10, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 72ms/step - accuracy: 0.8928 - loss: 0.2572 - val_accuracy: 0.9801 - val_loss: 0.0483\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9787 - loss: 0.0497 - val_accuracy: 0.9880 - val_loss: 0.0311\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 0.0293 - val_accuracy: 0.9871 - val_loss: 0.0398\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9945 - loss: 0.0146 - val_accuracy: 0.9851 - val_loss: 0.0383\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0147 - val_accuracy: 0.9861 - val_loss: 0.0334\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0134 - val_accuracy: 0.9771 - val_loss: 0.0627\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0126 - val_accuracy: 0.9880 - val_loss: 0.0372\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0161 - val_accuracy: 0.9841 - val_loss: 0.0408\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0077 - val_accuracy: 0.9851 - val_loss: 0.0458\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0138 - val_accuracy: 0.9871 - val_loss: 0.0610\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0110 - val_accuracy: 0.9791 - val_loss: 0.1050\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0139 - val_accuracy: 0.9841 - val_loss: 0.0743\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9958 - loss: 0.0117 - val_accuracy: 0.9851 - val_loss: 0.0636\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0062 - val_accuracy: 0.9851 - val_loss: 0.0693\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9953 - loss: 0.0129 - val_accuracy: 0.9851 - val_loss: 0.0759\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0051 - val_accuracy: 0.9851 - val_loss: 0.0786\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0083 - val_accuracy: 0.9831 - val_loss: 0.0662\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0079 - val_accuracy: 0.9841 - val_loss: 0.0492\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0074 - val_accuracy: 0.9851 - val_loss: 0.0636\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0081 - val_accuracy: 0.9811 - val_loss: 0.0806\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0016 - val_accuracy: 0.9851 - val_loss: 0.0707\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9831 - val_loss: 0.1186\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0362 - val_accuracy: 0.9821 - val_loss: 0.0911\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0043 - val_accuracy: 0.9811 - val_loss: 0.0952\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0055 - val_accuracy: 0.9880 - val_loss: 0.0776\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0060 - val_accuracy: 0.9851 - val_loss: 0.0556\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0038 - val_accuracy: 0.9871 - val_loss: 0.0760\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9950 - loss: 0.0125 - val_accuracy: 0.9851 - val_loss: 0.0995\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9955 - loss: 0.0139 - val_accuracy: 0.9841 - val_loss: 0.0778\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9980 - loss: 0.0085 - val_accuracy: 0.9900 - val_loss: 0.0440\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 0.0045 - val_accuracy: 0.9890 - val_loss: 0.0808\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9880 - val_loss: 0.0672\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9987 - loss: 0.0038 - val_accuracy: 0.9841 - val_loss: 0.0747\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9994 - loss: 0.0014 - val_accuracy: 0.9851 - val_loss: 0.0752\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0047 - val_accuracy: 0.9871 - val_loss: 0.0474\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9991 - loss: 0.0028 - val_accuracy: 0.9861 - val_loss: 0.0702\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0011 - val_accuracy: 0.9851 - val_loss: 0.1047\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0058 - val_accuracy: 0.9851 - val_loss: 0.1003\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0178 - val_accuracy: 0.9831 - val_loss: 0.0783\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0051 - val_accuracy: 0.9831 - val_loss: 0.0646\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0011 - val_accuracy: 0.9851 - val_loss: 0.0693\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0021 - val_accuracy: 0.9851 - val_loss: 0.0961\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0059 - val_accuracy: 0.9900 - val_loss: 0.0480\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9791 - val_loss: 0.1428\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0424 - val_accuracy: 0.9871 - val_loss: 0.1169\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9876 - loss: 0.0720 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 11, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 59ms/step - accuracy: 0.8957 - loss: 0.2487 - val_accuracy: 0.9831 - val_loss: 0.0457\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0258 - val_accuracy: 0.9841 - val_loss: 0.0429\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0177 - val_accuracy: 0.9831 - val_loss: 0.0431\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0219 - val_accuracy: 0.9880 - val_loss: 0.0410\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0145 - val_accuracy: 0.9811 - val_loss: 0.0469\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0091 - val_accuracy: 0.9841 - val_loss: 0.0416\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0095 - val_accuracy: 0.9821 - val_loss: 0.0598\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0135 - val_accuracy: 0.9801 - val_loss: 0.0927\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0094 - val_accuracy: 0.9861 - val_loss: 0.0488\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0059 - val_accuracy: 0.9861 - val_loss: 0.0535\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9929 - loss: 0.0271 - val_accuracy: 0.9851 - val_loss: 0.0661\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0150 - val_accuracy: 0.9861 - val_loss: 0.0551\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0096 - val_accuracy: 0.9890 - val_loss: 0.0427\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9988 - loss: 0.0029 - val_accuracy: 0.9761 - val_loss: 0.0891\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0141 - val_accuracy: 0.9880 - val_loss: 0.0638\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0025 - val_accuracy: 0.9910 - val_loss: 0.0521\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9981 - loss: 0.0100 - val_accuracy: 0.9880 - val_loss: 0.0536\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9974 - loss: 0.0084 - val_accuracy: 0.9890 - val_loss: 0.0449\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0025 - val_accuracy: 0.9880 - val_loss: 0.0698\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.0175 - val_accuracy: 0.9871 - val_loss: 0.0539\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0046 - val_accuracy: 0.9831 - val_loss: 0.0562\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9972 - loss: 0.0102 - val_accuracy: 0.9841 - val_loss: 0.0607\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9965 - loss: 0.0119 - val_accuracy: 0.9861 - val_loss: 0.0510\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0018 - val_accuracy: 0.9841 - val_loss: 0.0906\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0291 - val_accuracy: 0.9841 - val_loss: 0.0822\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0049 - val_accuracy: 0.9821 - val_loss: 0.0723\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0079 - val_accuracy: 0.9880 - val_loss: 0.0584\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0069 - val_accuracy: 0.9851 - val_loss: 0.0768\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9985 - loss: 0.0056 - val_accuracy: 0.9831 - val_loss: 0.0962\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0045 - val_accuracy: 0.9861 - val_loss: 0.0828\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0050 - val_accuracy: 0.9851 - val_loss: 0.0895\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0036 - val_accuracy: 0.9841 - val_loss: 0.0806\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 5.4787e-04 - val_accuracy: 0.9841 - val_loss: 0.0980\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0017 - val_accuracy: 0.9880 - val_loss: 0.0743\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0070 - val_accuracy: 0.9841 - val_loss: 0.0967\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0358 - val_accuracy: 0.9841 - val_loss: 0.0611\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0049 - val_accuracy: 0.9811 - val_loss: 0.1152\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0056 - val_accuracy: 0.9890 - val_loss: 0.0521\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0075 - val_accuracy: 0.9861 - val_loss: 0.0645\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0014 - val_accuracy: 0.9851 - val_loss: 0.0755\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 6.3782e-04 - val_accuracy: 0.9831 - val_loss: 0.1083\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0057 - val_accuracy: 0.9861 - val_loss: 0.0721\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0036 - val_accuracy: 0.9851 - val_loss: 0.0764\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3690e-04 - val_accuracy: 0.9861 - val_loss: 0.0921\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 5.3002e-04 - val_accuracy: 0.9871 - val_loss: 0.1098\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9859 - loss: 0.0887\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 12, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 61ms/step - accuracy: 0.9368 - loss: 0.2209 - val_accuracy: 0.9871 - val_loss: 0.0308\n",
            "Epoch 2/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0406 - val_accuracy: 0.9771 - val_loss: 0.0596\n",
            "Epoch 3/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0186 - val_accuracy: 0.9841 - val_loss: 0.0392\n",
            "Epoch 4/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0225 - val_accuracy: 0.9841 - val_loss: 0.0363\n",
            "Epoch 5/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9929 - loss: 0.0163 - val_accuracy: 0.9880 - val_loss: 0.0350\n",
            "Epoch 6/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9968 - loss: 0.0104 - val_accuracy: 0.9861 - val_loss: 0.0449\n",
            "Epoch 7/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0104 - val_accuracy: 0.9871 - val_loss: 0.0509\n",
            "Epoch 8/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0129 - val_accuracy: 0.9831 - val_loss: 0.0367\n",
            "Epoch 9/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0041 - val_accuracy: 0.9811 - val_loss: 0.0568\n",
            "Epoch 10/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0049 - val_accuracy: 0.9861 - val_loss: 0.0348\n",
            "Epoch 11/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0122 - val_accuracy: 0.9880 - val_loss: 0.0330\n",
            "Epoch 12/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0076 - val_accuracy: 0.9851 - val_loss: 0.0494\n",
            "Epoch 13/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0080 - val_accuracy: 0.9761 - val_loss: 0.1509\n",
            "Epoch 14/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0094 - val_accuracy: 0.9861 - val_loss: 0.0540\n",
            "Epoch 15/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 0.0011 - val_accuracy: 0.9841 - val_loss: 0.0638\n",
            "Epoch 16/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0064 - val_accuracy: 0.9821 - val_loss: 0.0674\n",
            "Epoch 17/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0073 - val_accuracy: 0.9890 - val_loss: 0.0416\n",
            "Epoch 18/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0145 - val_accuracy: 0.9851 - val_loss: 0.0551\n",
            "Epoch 19/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0032 - val_accuracy: 0.9851 - val_loss: 0.0416\n",
            "Epoch 20/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0079 - val_accuracy: 0.9861 - val_loss: 0.0561\n",
            "Epoch 21/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 5.8510e-04 - val_accuracy: 0.9861 - val_loss: 0.0619\n",
            "Epoch 22/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0205 - val_accuracy: 0.9821 - val_loss: 0.0794\n",
            "Epoch 23/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0034 - val_accuracy: 0.9880 - val_loss: 0.0597\n",
            "Epoch 24/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0133 - val_accuracy: 0.9861 - val_loss: 0.0546\n",
            "Epoch 25/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0041 - val_accuracy: 0.9861 - val_loss: 0.0583\n",
            "Epoch 26/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0109 - val_accuracy: 0.9861 - val_loss: 0.0363\n",
            "Epoch 27/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0051 - val_accuracy: 0.9871 - val_loss: 0.0555\n",
            "Epoch 28/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9982 - loss: 0.0084 - val_accuracy: 0.9841 - val_loss: 0.0597\n",
            "Epoch 29/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9997 - loss: 7.6213e-04 - val_accuracy: 0.9861 - val_loss: 0.0766\n",
            "Epoch 30/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0055 - val_accuracy: 0.9841 - val_loss: 0.0550\n",
            "Epoch 31/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9993 - loss: 0.0031 - val_accuracy: 0.9861 - val_loss: 0.0473\n",
            "Epoch 32/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9974 - loss: 0.0073 - val_accuracy: 0.9851 - val_loss: 0.0709\n",
            "Epoch 33/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9999 - loss: 8.2310e-04 - val_accuracy: 0.9841 - val_loss: 0.0979\n",
            "Epoch 34/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0062 - val_accuracy: 0.9890 - val_loss: 0.0868\n",
            "Epoch 35/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0149 - val_accuracy: 0.9861 - val_loss: 0.0681\n",
            "Epoch 36/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0028 - val_accuracy: 0.9861 - val_loss: 0.0810\n",
            "Epoch 37/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0019 - val_accuracy: 0.9871 - val_loss: 0.0783\n",
            "Epoch 38/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0025 - val_accuracy: 0.9861 - val_loss: 0.0751\n",
            "Epoch 39/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.5504e-04 - val_accuracy: 0.9841 - val_loss: 0.1005\n",
            "Epoch 40/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0024 - val_accuracy: 0.9880 - val_loss: 0.0598\n",
            "Epoch 41/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0053 - val_accuracy: 0.9841 - val_loss: 0.1039\n",
            "Epoch 42/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9358e-04 - val_accuracy: 0.9871 - val_loss: 0.0919\n",
            "Epoch 43/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9998 - loss: 3.3045e-04 - val_accuracy: 0.9861 - val_loss: 0.1111\n",
            "Epoch 44/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.4885e-04 - val_accuracy: 0.9811 - val_loss: 0.1547\n",
            "Epoch 45/45\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0194 - val_accuracy: 0.9880 - val_loss: 0.0852\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9942 - loss: 0.0520\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in l:\n",
        "  print(i[0],\"--->\",i[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LBtJhhzAFxuu",
        "outputId": "99e6bfc1-5ad3-4db8-d2a5-f880f7dd507f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 ---> 0.9860557913780212\n",
            "3 ---> 0.9900398254394531\n",
            "4 ---> 0.9890438318252563\n",
            "5 ---> 0.9910358786582947\n",
            "6 ---> 0.9910358786582947\n",
            "7 ---> 0.9900398254394531\n",
            "8 ---> 0.9810757040977478\n",
            "9 ---> 0.9900398254394531\n",
            "10 ---> 0.9850597381591797\n",
            "11 ---> 0.9860557913780212\n",
            "12 ---> 0.9900398254394531\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#45 epochs,0.25 split\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot([i[0] for i in l],[i[1]*100 for i in l])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "FFKOLkdSHogN",
        "outputId": "61a91a09-e692-4c6d-fe49-984b37d84f35"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x782b2fff0b80>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "k=[]\n",
        "for num_heads in range(2,13):\n",
        "  embed_dim = 32\n",
        "  ff_dim = 32\n",
        "  input_shape = X_train_scaled.shape[1]\n",
        "  inputs = layers.Input(shape=(input_shape,))\n",
        "  x = layers.Dense(embed_dim)(inputs)\n",
        "  transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "  x = transformer_block(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(64, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.1)(x)\n",
        "  x = layers.Dense(32, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.1)(x)\n",
        "  outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = models.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  model.fit(X_train_scaled, y_train, epochs=15, batch_size=32, validation_split=0.25)\n",
        "  loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "  k.append([num_heads,accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1Flnx3T7Hx9v",
        "outputId": "709d9364-7de9-4734-c6ae-ab87a81c0c8d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 65ms/step - accuracy: 0.9110 - loss: 0.2355 - val_accuracy: 0.9651 - val_loss: 0.0938\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9852 - loss: 0.0376 - val_accuracy: 0.9821 - val_loss: 0.0576\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9888 - loss: 0.0304 - val_accuracy: 0.9871 - val_loss: 0.0426\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0177 - val_accuracy: 0.9851 - val_loss: 0.0432\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9913 - loss: 0.0255 - val_accuracy: 0.9841 - val_loss: 0.0429\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9952 - loss: 0.0112 - val_accuracy: 0.9821 - val_loss: 0.0535\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0094 - val_accuracy: 0.9890 - val_loss: 0.0527\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0136 - val_accuracy: 0.9841 - val_loss: 0.0501\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0076 - val_accuracy: 0.9880 - val_loss: 0.0513\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0209 - val_accuracy: 0.9831 - val_loss: 0.0584\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0131 - val_accuracy: 0.9851 - val_loss: 0.0641\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0066 - val_accuracy: 0.9831 - val_loss: 0.0471\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9996 - loss: 0.0036 - val_accuracy: 0.9801 - val_loss: 0.0883\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0160 - val_accuracy: 0.9841 - val_loss: 0.0621\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0059 - val_accuracy: 0.9861 - val_loss: 0.0714\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9853 - loss: 0.0549 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 3, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.9207 - loss: 0.2100 - val_accuracy: 0.9861 - val_loss: 0.0362\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9877 - loss: 0.0325 - val_accuracy: 0.9871 - val_loss: 0.0379\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0209 - val_accuracy: 0.9871 - val_loss: 0.0402\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0219 - val_accuracy: 0.9880 - val_loss: 0.0452\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0177 - val_accuracy: 0.9851 - val_loss: 0.0434\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0139 - val_accuracy: 0.9841 - val_loss: 0.0453\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9960 - loss: 0.0131 - val_accuracy: 0.9831 - val_loss: 0.0588\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9958 - loss: 0.0203 - val_accuracy: 0.9831 - val_loss: 0.0695\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0148 - val_accuracy: 0.9851 - val_loss: 0.0498\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9961 - loss: 0.0104 - val_accuracy: 0.9861 - val_loss: 0.0577\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9930 - loss: 0.0195 - val_accuracy: 0.9821 - val_loss: 0.0919\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0210 - val_accuracy: 0.9861 - val_loss: 0.0676\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9955 - loss: 0.0086 - val_accuracy: 0.9801 - val_loss: 0.0807\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0057 - val_accuracy: 0.9861 - val_loss: 0.0678\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0070 - val_accuracy: 0.9851 - val_loss: 0.0610\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9927 - loss: 0.0398 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.8928 - loss: 0.2442 - val_accuracy: 0.9831 - val_loss: 0.0374\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9895 - loss: 0.0378 - val_accuracy: 0.9821 - val_loss: 0.0456\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9962 - loss: 0.0133 - val_accuracy: 0.9871 - val_loss: 0.0455\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0251 - val_accuracy: 0.9890 - val_loss: 0.0243\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.0131 - val_accuracy: 0.9880 - val_loss: 0.0317\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9960 - loss: 0.0099 - val_accuracy: 0.9861 - val_loss: 0.0394\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9937 - loss: 0.0191 - val_accuracy: 0.9861 - val_loss: 0.0525\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0087 - val_accuracy: 0.9861 - val_loss: 0.0619\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0123 - val_accuracy: 0.9871 - val_loss: 0.0601\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9812 - loss: 0.0803 - val_accuracy: 0.9890 - val_loss: 0.0502\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0084 - val_accuracy: 0.9841 - val_loss: 0.0556\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0077 - val_accuracy: 0.9871 - val_loss: 0.0565\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0046 - val_accuracy: 0.9871 - val_loss: 0.0662\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0190 - val_accuracy: 0.9880 - val_loss: 0.0541\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0051 - val_accuracy: 0.9851 - val_loss: 0.0565\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9938 - loss: 0.0282\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 5, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 60ms/step - accuracy: 0.9069 - loss: 0.2511 - val_accuracy: 0.9880 - val_loss: 0.0329\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9907 - loss: 0.0331 - val_accuracy: 0.9851 - val_loss: 0.0394\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0214 - val_accuracy: 0.9781 - val_loss: 0.0671\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0214 - val_accuracy: 0.9851 - val_loss: 0.0442\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0111 - val_accuracy: 0.9831 - val_loss: 0.0655\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0144 - val_accuracy: 0.9831 - val_loss: 0.0433\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0151 - val_accuracy: 0.9841 - val_loss: 0.0615\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9932 - loss: 0.0183 - val_accuracy: 0.9801 - val_loss: 0.0929\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0204 - val_accuracy: 0.9861 - val_loss: 0.0556\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0055 - val_accuracy: 0.9861 - val_loss: 0.0487\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0089 - val_accuracy: 0.9851 - val_loss: 0.0459\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0035 - val_accuracy: 0.9831 - val_loss: 0.0534\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0055 - val_accuracy: 0.9851 - val_loss: 0.0672\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0131 - val_accuracy: 0.9851 - val_loss: 0.0701\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9996 - loss: 0.0021 - val_accuracy: 0.9831 - val_loss: 0.0746\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9903 - loss: 0.0463 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 6, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 49ms/step - accuracy: 0.9204 - loss: 0.2185 - val_accuracy: 0.9631 - val_loss: 0.0816\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9649 - loss: 0.0823 - val_accuracy: 0.9801 - val_loss: 0.0530\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0254 - val_accuracy: 0.9880 - val_loss: 0.0402\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.0176 - val_accuracy: 0.9871 - val_loss: 0.0365\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9932 - loss: 0.0191 - val_accuracy: 0.9781 - val_loss: 0.0791\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.0196 - val_accuracy: 0.9900 - val_loss: 0.0289\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0110 - val_accuracy: 0.9851 - val_loss: 0.0357\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9965 - loss: 0.0108 - val_accuracy: 0.9771 - val_loss: 0.0543\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9903 - loss: 0.0243 - val_accuracy: 0.9900 - val_loss: 0.0435\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9885 - loss: 0.0331 - val_accuracy: 0.9821 - val_loss: 0.0534\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0047 - val_accuracy: 0.9871 - val_loss: 0.0776\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0197 - val_accuracy: 0.9841 - val_loss: 0.0595\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0066 - val_accuracy: 0.9801 - val_loss: 0.0863\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0102 - val_accuracy: 0.9871 - val_loss: 0.0558\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 0.9880 - val_loss: 0.0576\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9870 - loss: 0.0702 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 7, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - accuracy: 0.8807 - loss: 0.2599 - val_accuracy: 0.9771 - val_loss: 0.0595\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0392 - val_accuracy: 0.9890 - val_loss: 0.0301\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0235 - val_accuracy: 0.9791 - val_loss: 0.0545\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0277 - val_accuracy: 0.9821 - val_loss: 0.0440\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9957 - loss: 0.0124 - val_accuracy: 0.9831 - val_loss: 0.0601\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0182 - val_accuracy: 0.9861 - val_loss: 0.0504\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0112 - val_accuracy: 0.9821 - val_loss: 0.0700\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0258 - val_accuracy: 0.9801 - val_loss: 0.0497\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0086 - val_accuracy: 0.9831 - val_loss: 0.0611\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0143 - val_accuracy: 0.9841 - val_loss: 0.0462\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9916 - loss: 0.0144 - val_accuracy: 0.9871 - val_loss: 0.0545\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0095 - val_accuracy: 0.9831 - val_loss: 0.0589\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0031 - val_accuracy: 0.9801 - val_loss: 0.0648\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0128 - val_accuracy: 0.9871 - val_loss: 0.0467\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9983 - loss: 0.0072 - val_accuracy: 0.9890 - val_loss: 0.0532\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9909 - loss: 0.0252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.9295 - loss: 0.2104 - val_accuracy: 0.9851 - val_loss: 0.0343\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.9883 - loss: 0.0341 - val_accuracy: 0.9890 - val_loss: 0.0306\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0160 - val_accuracy: 0.9841 - val_loss: 0.0382\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9925 - loss: 0.0214 - val_accuracy: 0.9880 - val_loss: 0.0475\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9940 - loss: 0.0160 - val_accuracy: 0.9791 - val_loss: 0.0814\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9944 - loss: 0.0174 - val_accuracy: 0.9851 - val_loss: 0.0511\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9961 - loss: 0.0101 - val_accuracy: 0.9890 - val_loss: 0.0432\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9978 - loss: 0.0088 - val_accuracy: 0.9831 - val_loss: 0.0553\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9973 - loss: 0.0068 - val_accuracy: 0.9900 - val_loss: 0.0456\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0131 - val_accuracy: 0.9871 - val_loss: 0.0554\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0133 - val_accuracy: 0.9841 - val_loss: 0.0899\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9920 - loss: 0.0313 - val_accuracy: 0.9791 - val_loss: 0.0886\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9923 - loss: 0.0180 - val_accuracy: 0.9900 - val_loss: 0.0424\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9980 - loss: 0.0058 - val_accuracy: 0.9781 - val_loss: 0.0928\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0345 - val_accuracy: 0.9871 - val_loss: 0.0402\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 0.0321 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 9, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 66ms/step - accuracy: 0.8681 - loss: 0.2960 - val_accuracy: 0.9831 - val_loss: 0.0472\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9866 - loss: 0.0423 - val_accuracy: 0.9821 - val_loss: 0.0510\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9889 - loss: 0.0259 - val_accuracy: 0.9880 - val_loss: 0.0421\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0160 - val_accuracy: 0.9831 - val_loss: 0.0427\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0242 - val_accuracy: 0.9831 - val_loss: 0.0444\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9790 - loss: 0.0687 - val_accuracy: 0.9821 - val_loss: 0.0439\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9968 - loss: 0.0093 - val_accuracy: 0.9861 - val_loss: 0.0455\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0107 - val_accuracy: 0.9871 - val_loss: 0.0581\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0052 - val_accuracy: 0.9821 - val_loss: 0.0731\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9995 - loss: 0.0027 - val_accuracy: 0.9880 - val_loss: 0.0443\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0080 - val_accuracy: 0.9841 - val_loss: 0.0408\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0047 - val_accuracy: 0.9880 - val_loss: 0.0479\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0112 - val_accuracy: 0.9851 - val_loss: 0.0449\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0071 - val_accuracy: 0.9861 - val_loss: 0.0501\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9997 - loss: 0.0022 - val_accuracy: 0.9841 - val_loss: 0.0888\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9858 - loss: 0.0591 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 10, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 49ms/step - accuracy: 0.8822 - loss: 0.2733 - val_accuracy: 0.9831 - val_loss: 0.0459\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9905 - loss: 0.0332 - val_accuracy: 0.9612 - val_loss: 0.1030\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9501 - loss: 0.1334 - val_accuracy: 0.9841 - val_loss: 0.0525\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9928 - loss: 0.0214 - val_accuracy: 0.9831 - val_loss: 0.0516\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0110 - val_accuracy: 0.9821 - val_loss: 0.0550\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9927 - loss: 0.0164 - val_accuracy: 0.9841 - val_loss: 0.0667\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0166 - val_accuracy: 0.9841 - val_loss: 0.0696\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0275 - val_accuracy: 0.9851 - val_loss: 0.0560\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9965 - loss: 0.0098 - val_accuracy: 0.9871 - val_loss: 0.0630\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9997 - loss: 0.0026 - val_accuracy: 0.9871 - val_loss: 0.0676\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0122 - val_accuracy: 0.9861 - val_loss: 0.0611\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9956 - loss: 0.0104 - val_accuracy: 0.9861 - val_loss: 0.0586\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0044 - val_accuracy: 0.9781 - val_loss: 0.0837\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9993 - loss: 0.0056 - val_accuracy: 0.9851 - val_loss: 0.0474\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9930 - loss: 0.0179 - val_accuracy: 0.9851 - val_loss: 0.0512\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9937 - loss: 0.0366 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 11, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 71ms/step - accuracy: 0.8918 - loss: 0.2421 - val_accuracy: 0.9900 - val_loss: 0.0284\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9887 - loss: 0.0375 - val_accuracy: 0.9811 - val_loss: 0.0340\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0236 - val_accuracy: 0.9821 - val_loss: 0.0428\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9912 - loss: 0.0290 - val_accuracy: 0.9791 - val_loss: 0.0604\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0170 - val_accuracy: 0.9851 - val_loss: 0.0317\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9918 - loss: 0.0145 - val_accuracy: 0.9851 - val_loss: 0.0390\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0064 - val_accuracy: 0.9851 - val_loss: 0.0402\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0120 - val_accuracy: 0.9871 - val_loss: 0.0336\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0064 - val_accuracy: 0.9761 - val_loss: 0.1210\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0199 - val_accuracy: 0.9861 - val_loss: 0.0492\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9979 - loss: 0.0077 - val_accuracy: 0.9871 - val_loss: 0.0493\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0097 - val_accuracy: 0.9861 - val_loss: 0.0332\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9942 - loss: 0.0157 - val_accuracy: 0.9851 - val_loss: 0.0515\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0109 - val_accuracy: 0.9731 - val_loss: 0.1313\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0245 - val_accuracy: 0.9821 - val_loss: 0.0565\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9949 - loss: 0.0263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 12, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 50ms/step - accuracy: 0.8985 - loss: 0.2338 - val_accuracy: 0.9741 - val_loss: 0.0641\n",
            "Epoch 2/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9876 - loss: 0.0379 - val_accuracy: 0.9851 - val_loss: 0.0380\n",
            "Epoch 3/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9915 - loss: 0.0203 - val_accuracy: 0.9821 - val_loss: 0.0406\n",
            "Epoch 4/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9931 - loss: 0.0177 - val_accuracy: 0.9831 - val_loss: 0.0449\n",
            "Epoch 5/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0142 - val_accuracy: 0.9890 - val_loss: 0.0393\n",
            "Epoch 6/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9963 - loss: 0.0109 - val_accuracy: 0.9851 - val_loss: 0.0367\n",
            "Epoch 7/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0076 - val_accuracy: 0.9821 - val_loss: 0.0468\n",
            "Epoch 8/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0134 - val_accuracy: 0.9861 - val_loss: 0.0378\n",
            "Epoch 9/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0071 - val_accuracy: 0.9761 - val_loss: 0.0901\n",
            "Epoch 10/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0236 - val_accuracy: 0.9861 - val_loss: 0.0519\n",
            "Epoch 11/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9977 - loss: 0.0110 - val_accuracy: 0.9851 - val_loss: 0.0375\n",
            "Epoch 12/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9935 - loss: 0.0163 - val_accuracy: 0.9841 - val_loss: 0.0410\n",
            "Epoch 13/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9941 - loss: 0.0120 - val_accuracy: 0.9851 - val_loss: 0.0742\n",
            "Epoch 14/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.0175 - val_accuracy: 0.9851 - val_loss: 0.0528\n",
            "Epoch 15/15\n",
            "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9989 - loss: 0.0043 - val_accuracy: 0.9861 - val_loss: 0.0910\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0557\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in k:\n",
        "  print(i[0],\"--->\",i[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "LtwCSSbeKZ09",
        "outputId": "9b485aa1-ed55-4f18-ac0c-90e89aff620a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 ---> 0.9860557913780212\n",
            "3 ---> 0.9910358786582947\n",
            "4 ---> 0.9920318722724915\n",
            "5 ---> 0.9890438318252563\n",
            "6 ---> 0.9860557913780212\n",
            "7 ---> 0.9890438318252563\n",
            "8 ---> 0.9900398254394531\n",
            "9 ---> 0.9860557913780212\n",
            "10 ---> 0.9890438318252563\n",
            "11 ---> 0.9910358786582947\n",
            "12 ---> 0.9880478382110596\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15 epochs,0.25 split\n",
        "plt.plot([i[0] for i in k],[i[1]*100 for i in k])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "dP0tThjAKaHk",
        "outputId": "cf839863-1a73-4dfd-966b-e1b5f70aa0ff"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x782b2ff7e530>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t=[]\n",
        "for num_heads in range(2,13):\n",
        "  embed_dim = 32\n",
        "  ff_dim = 32\n",
        "  input_shape = X_train_scaled.shape[1]\n",
        "  inputs = layers.Input(shape=(input_shape,))\n",
        "  x = layers.Dense(embed_dim)(inputs)\n",
        "  transformer_block = TransformerBlock(embed_dim, num_heads, ff_dim)\n",
        "  x = transformer_block(x)\n",
        "  x = layers.Flatten()(x)\n",
        "  x = layers.Dense(64, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.1)(x)\n",
        "  x = layers.Dense(32, activation=\"relu\")(x)\n",
        "  x = layers.Dropout(0.1)(x)\n",
        "  outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "\n",
        "  model = models.Model(inputs=inputs, outputs=outputs)\n",
        "  model.compile(optimizer='adam',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  model.fit(X_train_scaled, y_train, epochs=15, batch_size=32, validation_split=0.20)\n",
        "  loss, accuracy = model.evaluate(X_test_scaled, y_test)\n",
        "  t.append([num_heads,accuracy])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "MfHW_pX4KqQy",
        "outputId": "e0c7d4f9-9b22-4625-b2fc-0f642499bc0d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 2, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 69ms/step - accuracy: 0.8980 - loss: 0.2442 - val_accuracy: 0.9875 - val_loss: 0.0335\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.0359 - val_accuracy: 0.9888 - val_loss: 0.0395\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.0311 - val_accuracy: 0.9875 - val_loss: 0.0456\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9854 - loss: 0.0313 - val_accuracy: 0.9863 - val_loss: 0.0357\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.0114 - val_accuracy: 0.9875 - val_loss: 0.0436\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9980 - loss: 0.0065 - val_accuracy: 0.9863 - val_loss: 0.0444\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9967 - loss: 0.0094 - val_accuracy: 0.9851 - val_loss: 0.0427\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9985 - loss: 0.0080 - val_accuracy: 0.9863 - val_loss: 0.0426\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0113 - val_accuracy: 0.9888 - val_loss: 0.0384\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0076 - val_accuracy: 0.9863 - val_loss: 0.0469\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9974 - loss: 0.0062 - val_accuracy: 0.9875 - val_loss: 0.0372\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0090 - val_accuracy: 0.9851 - val_loss: 0.0437\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0063 - val_accuracy: 0.9676 - val_loss: 0.1098\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0214 - val_accuracy: 0.9838 - val_loss: 0.0529\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0043 - val_accuracy: 0.9851 - val_loss: 0.0668\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9821 - loss: 0.0648\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 3, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 59ms/step - accuracy: 0.8840 - loss: 0.2717 - val_accuracy: 0.9900 - val_loss: 0.0432\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9843 - loss: 0.0429 - val_accuracy: 0.9875 - val_loss: 0.0368\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0176 - val_accuracy: 0.9763 - val_loss: 0.1074\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9832 - loss: 0.0412 - val_accuracy: 0.9900 - val_loss: 0.0487\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0239 - val_accuracy: 0.9863 - val_loss: 0.0604\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9960 - loss: 0.0131 - val_accuracy: 0.9838 - val_loss: 0.0517\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0101 - val_accuracy: 0.9863 - val_loss: 0.0482\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0107 - val_accuracy: 0.9863 - val_loss: 0.0573\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0115 - val_accuracy: 0.9888 - val_loss: 0.0644\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0075 - val_accuracy: 0.9875 - val_loss: 0.0536\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0127 - val_accuracy: 0.9851 - val_loss: 0.0557\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0068 - val_accuracy: 0.9888 - val_loss: 0.0525\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9946 - loss: 0.0094 - val_accuracy: 0.9875 - val_loss: 0.0696\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9975 - loss: 0.0039 - val_accuracy: 0.9875 - val_loss: 0.0652\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9975 - loss: 0.0073 - val_accuracy: 0.9888 - val_loss: 0.0671\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9819 - loss: 0.0572\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 4, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 65ms/step - accuracy: 0.8992 - loss: 0.2550 - val_accuracy: 0.9788 - val_loss: 0.0589\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9903 - loss: 0.0344 - val_accuracy: 0.9863 - val_loss: 0.0335\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0264 - val_accuracy: 0.9776 - val_loss: 0.0576\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0160 - val_accuracy: 0.9888 - val_loss: 0.0307\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9949 - loss: 0.0152 - val_accuracy: 0.9888 - val_loss: 0.0360\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9917 - loss: 0.0204 - val_accuracy: 0.9838 - val_loss: 0.0403\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0138 - val_accuracy: 0.9888 - val_loss: 0.0394\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0119 - val_accuracy: 0.9826 - val_loss: 0.0441\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0095 - val_accuracy: 0.9863 - val_loss: 0.0370\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9965 - loss: 0.0081 - val_accuracy: 0.9851 - val_loss: 0.0369\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0110 - val_accuracy: 0.9851 - val_loss: 0.0368\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0120 - val_accuracy: 0.9888 - val_loss: 0.0382\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0062 - val_accuracy: 0.9863 - val_loss: 0.0398\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0102 - val_accuracy: 0.9851 - val_loss: 0.0490\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9993 - loss: 0.0023 - val_accuracy: 0.9863 - val_loss: 0.0427\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9918 - loss: 0.0262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 5, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - accuracy: 0.9236 - loss: 0.2129 - val_accuracy: 0.9851 - val_loss: 0.0417\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0266 - val_accuracy: 0.9826 - val_loss: 0.0479\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9901 - loss: 0.0306 - val_accuracy: 0.9900 - val_loss: 0.0337\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0158 - val_accuracy: 0.9813 - val_loss: 0.0615\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0134 - val_accuracy: 0.9875 - val_loss: 0.0313\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0079 - val_accuracy: 0.9913 - val_loss: 0.0411\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0162 - val_accuracy: 0.9875 - val_loss: 0.0383\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0103 - val_accuracy: 0.9763 - val_loss: 0.0964\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9952 - loss: 0.0167 - val_accuracy: 0.9913 - val_loss: 0.0559\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9964 - loss: 0.0139 - val_accuracy: 0.9913 - val_loss: 0.0396\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9992 - loss: 0.0030 - val_accuracy: 0.9900 - val_loss: 0.0425\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9959 - loss: 0.0170 - val_accuracy: 0.9863 - val_loss: 0.0357\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9985 - loss: 0.0049 - val_accuracy: 0.9875 - val_loss: 0.0491\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.0081 - val_accuracy: 0.9888 - val_loss: 0.0402\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9994 - loss: 0.0032 - val_accuracy: 0.9863 - val_loss: 0.0528\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9826 - loss: 0.0487\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 6, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 69ms/step - accuracy: 0.9155 - loss: 0.2323 - val_accuracy: 0.9851 - val_loss: 0.0334\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 5ms/step - accuracy: 0.9905 - loss: 0.0278 - val_accuracy: 0.9888 - val_loss: 0.0398\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9923 - loss: 0.0226 - val_accuracy: 0.9851 - val_loss: 0.0423\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9941 - loss: 0.0184 - val_accuracy: 0.9888 - val_loss: 0.0394\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9933 - loss: 0.0170 - val_accuracy: 0.9875 - val_loss: 0.0353\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0098 - val_accuracy: 0.9900 - val_loss: 0.0338\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0131 - val_accuracy: 0.9900 - val_loss: 0.0369\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0085 - val_accuracy: 0.9888 - val_loss: 0.0543\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0110 - val_accuracy: 0.9913 - val_loss: 0.0419\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9979 - loss: 0.0053 - val_accuracy: 0.9875 - val_loss: 0.0758\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9906 - loss: 0.0365 - val_accuracy: 0.9900 - val_loss: 0.0397\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9961 - loss: 0.0122 - val_accuracy: 0.9875 - val_loss: 0.0620\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0149 - val_accuracy: 0.9875 - val_loss: 0.0692\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9962 - loss: 0.0067 - val_accuracy: 0.9863 - val_loss: 0.0661\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0060 - val_accuracy: 0.9838 - val_loss: 0.0784\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9882 - loss: 0.0481\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 7, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 64ms/step - accuracy: 0.8936 - loss: 0.2462 - val_accuracy: 0.9900 - val_loss: 0.0383\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9872 - loss: 0.0461 - val_accuracy: 0.9851 - val_loss: 0.0420\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0298 - val_accuracy: 0.9913 - val_loss: 0.0479\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0303 - val_accuracy: 0.9875 - val_loss: 0.0307\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9957 - loss: 0.0111 - val_accuracy: 0.9888 - val_loss: 0.0266\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.0107 - val_accuracy: 0.9838 - val_loss: 0.0590\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9946 - loss: 0.0134 - val_accuracy: 0.9875 - val_loss: 0.0310\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9986 - loss: 0.0051 - val_accuracy: 0.9851 - val_loss: 0.0589\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.0141 - val_accuracy: 0.9888 - val_loss: 0.0347\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9984 - loss: 0.0059 - val_accuracy: 0.9826 - val_loss: 0.0887\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0049 - val_accuracy: 0.9863 - val_loss: 0.0463\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0148 - val_accuracy: 0.9838 - val_loss: 0.0904\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0109 - val_accuracy: 0.9801 - val_loss: 0.0630\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9951 - loss: 0.0129 - val_accuracy: 0.9900 - val_loss: 0.0462\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0024 - val_accuracy: 0.9900 - val_loss: 0.0414\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9932 - loss: 0.0377\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 8, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 61ms/step - accuracy: 0.9074 - loss: 0.2383 - val_accuracy: 0.9913 - val_loss: 0.0262\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9900 - loss: 0.0262 - val_accuracy: 0.9601 - val_loss: 0.1182\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9833 - loss: 0.0379 - val_accuracy: 0.9913 - val_loss: 0.0445\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9834 - loss: 0.0699 - val_accuracy: 0.9863 - val_loss: 0.0468\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9950 - loss: 0.0129 - val_accuracy: 0.9875 - val_loss: 0.0419\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.9900 - val_loss: 0.0461\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9940 - loss: 0.0127 - val_accuracy: 0.9913 - val_loss: 0.0417\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0074 - val_accuracy: 0.9900 - val_loss: 0.0348\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0155 - val_accuracy: 0.9875 - val_loss: 0.0405\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0116 - val_accuracy: 0.9888 - val_loss: 0.0420\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0091 - val_accuracy: 0.9913 - val_loss: 0.0447\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0068 - val_accuracy: 0.9913 - val_loss: 0.0332\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9987 - loss: 0.0050 - val_accuracy: 0.9875 - val_loss: 0.0443\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9973 - loss: 0.0062 - val_accuracy: 0.9900 - val_loss: 0.0721\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0089 - val_accuracy: 0.9875 - val_loss: 0.0495\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9910 - loss: 0.0370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 9, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.8795 - loss: 0.2603 - val_accuracy: 0.9738 - val_loss: 0.0718\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.0399 - val_accuracy: 0.9888 - val_loss: 0.0329\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0233 - val_accuracy: 0.9863 - val_loss: 0.0358\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0186 - val_accuracy: 0.9863 - val_loss: 0.0397\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0148 - val_accuracy: 0.9826 - val_loss: 0.0681\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0168 - val_accuracy: 0.9826 - val_loss: 0.0509\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9825 - loss: 0.0320 - val_accuracy: 0.9838 - val_loss: 0.0708\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9953 - loss: 0.0125 - val_accuracy: 0.9863 - val_loss: 0.0433\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0095 - val_accuracy: 0.9888 - val_loss: 0.0466\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9948 - loss: 0.0153 - val_accuracy: 0.9875 - val_loss: 0.0522\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0114 - val_accuracy: 0.9888 - val_loss: 0.0510\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9982 - loss: 0.0068 - val_accuracy: 0.9888 - val_loss: 0.0533\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9966 - loss: 0.0100 - val_accuracy: 0.9875 - val_loss: 0.0526\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9976 - loss: 0.0075 - val_accuracy: 0.9875 - val_loss: 0.0729\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0051 - val_accuracy: 0.9763 - val_loss: 0.1124\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9832 - loss: 0.0878\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 10, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 53ms/step - accuracy: 0.9119 - loss: 0.2330 - val_accuracy: 0.9813 - val_loss: 0.0472\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9894 - loss: 0.0325 - val_accuracy: 0.9813 - val_loss: 0.0404\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9911 - loss: 0.0268 - val_accuracy: 0.9875 - val_loss: 0.0282\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9939 - loss: 0.0203 - val_accuracy: 0.9875 - val_loss: 0.0303\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9926 - loss: 0.0144 - val_accuracy: 0.9900 - val_loss: 0.0336\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0115 - val_accuracy: 0.9826 - val_loss: 0.0535\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9914 - loss: 0.0214 - val_accuracy: 0.9639 - val_loss: 0.1037\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9924 - loss: 0.0208 - val_accuracy: 0.9863 - val_loss: 0.0430\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0078 - val_accuracy: 0.9813 - val_loss: 0.0630\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0087 - val_accuracy: 0.9851 - val_loss: 0.0377\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9962 - loss: 0.0101 - val_accuracy: 0.9875 - val_loss: 0.0329\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0046 - val_accuracy: 0.9900 - val_loss: 0.0373\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0058 - val_accuracy: 0.9888 - val_loss: 0.0413\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9981 - loss: 0.0074 - val_accuracy: 0.9900 - val_loss: 0.0469\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9989 - loss: 0.0060 - val_accuracy: 0.9900 - val_loss: 0.0401\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9901 - loss: 0.0316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 11, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 70ms/step - accuracy: 0.9214 - loss: 0.1925 - val_accuracy: 0.9813 - val_loss: 0.0415\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9838 - loss: 0.0445 - val_accuracy: 0.9888 - val_loss: 0.0373\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0185 - val_accuracy: 0.9863 - val_loss: 0.0324\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9935 - loss: 0.0130 - val_accuracy: 0.9851 - val_loss: 0.0396\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9959 - loss: 0.0119 - val_accuracy: 0.9776 - val_loss: 0.0687\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0248 - val_accuracy: 0.9900 - val_loss: 0.0513\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9934 - loss: 0.0143 - val_accuracy: 0.9763 - val_loss: 0.0865\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9909 - loss: 0.0165 - val_accuracy: 0.9863 - val_loss: 0.0496\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9944 - loss: 0.0163 - val_accuracy: 0.9851 - val_loss: 0.0393\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9955 - loss: 0.0137 - val_accuracy: 0.9900 - val_loss: 0.0280\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0120 - val_accuracy: 0.9875 - val_loss: 0.0345\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9970 - loss: 0.0101 - val_accuracy: 0.9863 - val_loss: 0.0449\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9967 - loss: 0.0102 - val_accuracy: 0.9875 - val_loss: 0.0618\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9945 - loss: 0.0139 - val_accuracy: 0.9875 - val_loss: 0.0441\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9986 - loss: 0.0072 - val_accuracy: 0.9863 - val_loss: 0.0393\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9896 - loss: 0.0201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/ops/nn.py:545: UserWarning: You are using a softmax over axis 3 of a tensor of shape (None, 12, 1, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 53ms/step - accuracy: 0.9218 - loss: 0.2155 - val_accuracy: 0.9851 - val_loss: 0.0362\n",
            "Epoch 2/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9897 - loss: 0.0315 - val_accuracy: 0.9826 - val_loss: 0.0450\n",
            "Epoch 3/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0342 - val_accuracy: 0.9863 - val_loss: 0.0398\n",
            "Epoch 4/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9938 - loss: 0.0149 - val_accuracy: 0.9863 - val_loss: 0.0399\n",
            "Epoch 5/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0361 - val_accuracy: 0.9788 - val_loss: 0.0668\n",
            "Epoch 6/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9954 - loss: 0.0146 - val_accuracy: 0.9888 - val_loss: 0.0644\n",
            "Epoch 7/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9922 - loss: 0.0246 - val_accuracy: 0.9851 - val_loss: 0.0479\n",
            "Epoch 8/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9964 - loss: 0.0100 - val_accuracy: 0.9851 - val_loss: 0.0498\n",
            "Epoch 9/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9954 - loss: 0.0086 - val_accuracy: 0.9851 - val_loss: 0.0496\n",
            "Epoch 10/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9937 - loss: 0.0154 - val_accuracy: 0.9851 - val_loss: 0.0534\n",
            "Epoch 11/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9992 - loss: 0.0061 - val_accuracy: 0.9875 - val_loss: 0.0494\n",
            "Epoch 12/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9994 - loss: 0.0056 - val_accuracy: 0.9875 - val_loss: 0.0500\n",
            "Epoch 13/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.0076 - val_accuracy: 0.9888 - val_loss: 0.0570\n",
            "Epoch 14/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9948 - loss: 0.0169 - val_accuracy: 0.9863 - val_loss: 0.0811\n",
            "Epoch 15/15\n",
            "\u001b[1m101/101\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0054 - val_accuracy: 0.9863 - val_loss: 0.0618\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9916 - loss: 0.0235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in t:\n",
        "  print(i[0],\"--->\",i[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sWF7yv0EKzOZ",
        "outputId": "7cd08f5a-d1e8-4ada-e731-e3198dc26ec6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2 ---> 0.9850597381591797\n",
            "3 ---> 0.9850597381591797\n",
            "4 ---> 0.9900398254394531\n",
            "5 ---> 0.9840637445449829\n",
            "6 ---> 0.987051784992218\n",
            "7 ---> 0.987051784992218\n",
            "8 ---> 0.9890438318252563\n",
            "9 ---> 0.9840637445449829\n",
            "10 ---> 0.9890438318252563\n",
            "11 ---> 0.9910358786582947\n",
            "12 ---> 0.9910358786582947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15 epochs,0.20 valid split\n",
        "plt.plot([i[0] for i in t],[i[1]*100 for i in t])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "f8104xwyL-uL",
        "outputId": "40c72844-f64b-4fd0-fe22-aaae527f2e5e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x782b0c1afd30>]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJ1h1MYoMGe8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}